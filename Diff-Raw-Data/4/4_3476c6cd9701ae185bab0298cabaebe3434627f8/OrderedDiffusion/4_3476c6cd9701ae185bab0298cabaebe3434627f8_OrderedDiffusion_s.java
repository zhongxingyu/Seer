 package nardiff.ordered;
 
 import java.util.ArrayList;
 import java.util.HashSet;
 import java.util.List;
 import java.util.Set;
 
 import nardiff.DataOutputFile;
 import nardiff.MersenneTwisterFast;
 import nardiff.Person;
 import nardiff.Relationship;
 import nardiff.SocialGraph;
 import nardiff.ThreadPoolRunner;
 
 import org.apache.commons.collections15.Factory;
 
 import edu.uci.ics.jung.algorithms.generators.random.BarabasiAlbertGenerator;
 import edu.uci.ics.jung.graph.Graph;
 import edu.uci.ics.jung.graph.util.Pair;
 
 /**
  * This is the top-level simulation class for the narrative diffusion simulation
  * using ordered information. This is the class that contains the top-level
  * information for the simulation; after the appropriate setup has taken place,
  * calling this class's run() method executes the simulation. Each instance
  * calls a static member that coordinates data output between them.
  * 
  * Additionally, this class has a main() method that sets up a large number of
  * OrderedDiffusion models and executes them. To take advantage of multi-core
  * processors, and because each simulation is independent of all others, this
  * uses a Java ThreadPool to manage simultaneous execution of models in a thread
  * pool. The size of this pool is configurable based on a default in source code
  * and a parameter that can be passed to main().
  * 
  * 
  * @author kkoning
  * 
  */
 /**
  * @author kkoning
  * 
  */
 public class OrderedDiffusion implements Runnable {
 
 	// Parameters
 	/**
 	 * When adding vertices (people) to the graph, the graph creation algorithm
 	 * we use requires us to specify the number of attachments to make to other
 	 * vertices. This variable must be initialized on setup and is passed to
 	 * that graph creation algorithm.
 	 */
 	public int numAttachments;
 
 	/**
 	 * Currently, the graph is created and fixed at initialization time. This
 	 * parameter specifies the number of individuals that will be present in the
 	 * social graph.
 	 */
 	public int totalPopulation;
 
 	/**
 	 * This parameter specifies the total number of information pieces that may
 	 * be present in the model. These are represented as positive 8-bit integers
 	 * (type byte), so the largest number here should be 256. In practice,
 	 * computational limits created by other algorithms will limit this to a
 	 * smaller number.
 	 * 
 	 * For example, if this variable is 5, then the complete ordered set of
 	 * information pieces is the ordered set {0,1,2,3,4}
 	 */
 	public int numTotalInfoPieces;
 
 	/**
 	 * When each vertex (person) is created, its current set of knowledge
 	 * contains this many information pieces. This parameter must be less than
 	 * numTotalInfoPieces.
 	 */
 	public int numInitialInfoPieces;
 
 	/**
 	 * During the reorder() function, the person will investigate a number of
 	 * possible orderings, generated by flipping random bytes within the
 	 * knowledge vector. If this is set to a low number, the odds of finding a
 	 * flip that does improve the ordering score is lower than if there are a
 	 * large number of flips. This variable is used in the
 	 * getCandidateOrderings() function, which determines which of those
 	 * possible flips to pass on to the reorder() function to weigh and select.
 	 */
 	public int flipsToCheck;
 
 	/**
 	 * This is a model-level parameter for adjusting the probability that a
 	 * piece of knowledge will be transmitted. It is used to scale the computed
 	 * probabilities based on inter-person similarity.
 	 */
 	public float probKnowledgeXmit;
 
 	/**
 	 * When comparing similarity between people and calculating a knowledge
 	 * transmission probability score based on that, use this number as the
 	 * lower bound on that probability--scale between this and
 	 * similarityProbMax.
 	 */
 	public float similarityProbMin;
 
 	/**
 	 * When comparing similarity between people and calculating a knowledge
 	 * transmission probability score based on that, use this number as the
 	 * upper bound on that probability--scale between this and
 	 * similarityProbMin.
 	 */
 	public float similarityProbMax;
 
 	/**
 	 * This parameter specifies the weight that each vertex (person) places on
 	 * consistency (as measured by proportional Levenshtein distance) of
 	 * candidate strings with an ideally ordered list, as opposed to the mean
 	 * consistency of its neighbor's strings (1-alpha)
 	 */
 	public float alpha;
 
 	/**
 	 * This parameter specifies the probability that, each turn, a given vertex
 	 * (person) will change the order of their knowledge pieces in a way that
 	 * reduces the total # of inversions present in its knowledge set.
 	 */
 	public float reorderProb;
 
 	/**
 	 * This contains the random seed for this particular model. Because the
 	 * models are run with the assumption of isolation from each other, it is
 	 * important for repeat-ability that the source of (psuedo-) randomness is
 	 * isolated to this instance.
 	 */
 	public MersenneTwisterFast random;
 
 	/**
 	 * Save the random seed for data output.
 	 */
 	public long randomSeed;
 
 	/**
 	 * The maximum number of steps to run this model.
 	 */
 	public int stepsLimit;
 
 	// Runtime Variables
 	/**
 	 * This is a run-time variable that tracks the # of steps the model has been
 	 * executed.
 	 */
 	int steps = 0;
 
 	/**
 	 * This is a run-time variable that contains the social graph.
 	 */
 	SocialGraph graph;
 
 	/**
 	 * This static run-time variable is shared between all instances of the
 	 * OrderedDiffusion class. Its function is to coordinate data output between
 	 * a number of different threads writing the same formatted data.
 	 */
 	static DataOutputFile out;
 
 	/**
 	 * Unique incrementing counter for each model, allows identification.
 	 */
 	public int modelID = 0;
 
 	/**
 	 * The total # of these models created so far in this run. Used to increment
 	 * set modelID.
 	 */
 	public static int modelsCreated = 0;
 
 	/**
 	 * This is the main() class that is called to run the data-generating
 	 * procedure that creates instances of OrderedDiffusion and then executes
 	 * them.
 	 * 
 	 * The specific parameters used in the model are drawn from a flat random
 	 * distribution which is hard coded within this source file. This could be
 	 * externalized in a separate parameters file in the future, if necessary.
 	 * 
 	 * The number of observations is hard-coded here, with local parameter 'n'.
 	 * 
 	 * @param args
 	 *            It takes two arguments. The first is the output file name,
 	 *            which defaults to "nardiff.ordered.tsv". The second is the
 	 *            number of threads used to simultaneously execute
 	 *            OrderedDiffusion models. It defaults to 4.
 	 */
 	public static void main(String[] args) {
 
 		// The # of observations
 		int n = 200;
 
 		// Initialize the data output file.
 		String outputFilename = "nardiff.ordered.tsv";
 		if (args.length != 0)
 			if (args[0] != null)
 				outputFilename = args[0];
 
 		MersenneTwisterFast mainRandom = new MersenneTwisterFast(1);
 		if (out == null) {
 			String[] colNames = new String[17];
 			colNames[0] = "modelID";
 			colNames[1] = "randomSeed";
 			colNames[2] = "numPeople";
 			colNames[3] = "numAttachmentsOnAdd";
 			colNames[4] = "knowledgeVectorSize";
 			colNames[5] = "knowledgeVectorInitialFill";
 			colNames[6] = "probKnowledgeXmit";
 			colNames[7] = "avgDegree";
 			colNames[8] = "alpha";
 			colNames[9] = "reorderProb";
 			colNames[10] = "step";
 			colNames[11] = "meanElementsPerPerson";
 			colNames[12] = "meanProportionOfTotalKnowledge";
 			colNames[13] = "meanSeenTruthScore";
 			colNames[14] = "meanTotalTruthScore";
 			colNames[15] = "ratioTotalKnowledge";
 			colNames[16] = "ratioTotalOrderedKnowledge";
 
 			out = new DataOutputFile(outputFilename, colNames);
 		}
 
 		// Initialize the thread pool for running OrderedDiffusion simulations
 		int numThreads = 1;
 		if (args.length != 0)
 			try {
 				Integer threads = Integer.parseInt(args[1]);
 				if (threads != null)
 					numThreads = threads;
 			} catch (Exception e) {
 				// do nothing, just use the default = 4;
 			}
 		ThreadPoolRunner tpr = new ThreadPoolRunner(numThreads);
 
 		/*
 		 * This is the primary loop for creation of OrderedDiffusion models and
 		 * the initialization of the necessary parameters. These are currently
 		 * initialized based on a random selection within a range that is
 		 * hard-coded here in the source code.
 		 */
 		for (int obs = 0; obs < n; obs++) {
 
 			// TODO: Document all parameters in narrative descrition of model.
 			final OrderedDiffusion od = new OrderedDiffusion();
 			od.numAttachments = mainRandom.nextInt(7) + 1;
 			od.totalPopulation = 300;
 			od.numTotalInfoPieces = mainRandom.nextInt(10) + 10;
 			od.numInitialInfoPieces = mainRandom.nextInt(6) + 3;
 			od.probKnowledgeXmit = 1; // use similarity metric only for now.
 			od.alpha = mainRandom.nextFloat(false, false);
 			od.reorderProb = mainRandom.nextFloat(false, false);
 			od.flipsToCheck = 15;
 			od.stepsLimit = 310;
 			od.similarityProbMin = 0.2f;
 			od.similarityProbMax = 0.8f;
 			od.modelID = modelsCreated++;
 
 			od.randomSeed = mainRandom.nextLong();
 			od.random = new MersenneTwisterFast(od.randomSeed);
 
 			final int o = obs;
 
 			tpr.runModel(new Runnable() {
 				@Override
 				public void run() {
 					try {
 						od.run();
 					} catch (Exception ex) {
 						ex.printStackTrace();
 						System.exit(-1);
 					}
 					System.out.println("Finished Obs " + o);
 				}
 
 			});
 
 		}
 
 		tpr.finish();
 
 	}
 
 	/**
 	 * This is the graph creation algorithm used by this model at initialization
 	 * time. It makes used of the BarabassiAlbertGenerator from the JUNG project
 	 * to actually generate the graphs. This function is called in the run()
 	 * method as part of initialization.
 	 * 
 	 * This requires creating graph, vertex, and edge creation 'factory' classes
 	 * following the factory software design pattern.
 	 * 
 	 * <ul>
 	 * <li>The graph creation factory simply calls the no-argument constructor
 	 * for SocialGraph. There is no special data stored along with the graph
 	 * overall, apart from that which is stored in this top-level class.</li>
 	 * 
 	 * <li>The edge creation factory also simply calls the no-argument
 	 * constructor for OrderedRelationship. Relationships have no special data
 	 * stored with them; each edge/relationship, if it exists, is exactly the
 	 * same as all others.</li>
 	 * 
 	 * <li>The vertex/person creation factory is slightly more complex. It has
 	 * its own class for implementation, which is referenced below. However,
 	 * this method passes on some parameters to that factory's constructor.
 	 * Specifically, these are a reference to the models random source,
 	 * numTotalInfoPieces, inversionsWeight, and reorderProb, as these
 	 * parameters are necessary to create each vertex/person in the model.
 	 * </ul>
 	 * 
 	 * @see nardiff.SocialGraph
 	 * @see nardiff.ordered.OrderedPersonFactory
 	 * @see nardiff.ordered.OrderedRelationship
 	 * @see nardiff.ordered.OrderedPerson
 	 * 
 	 */
 	public void createGraph() {
 
 		Factory<Graph<Person, Relationship>> graphFactory = new Factory<Graph<Person, Relationship>>() {
 			@Override
 			public Graph<Person, Relationship> create() {
 				return new SocialGraph();
 			}
 		};
 
 		Factory<Person> vertexFactory = new OrderedPersonFactory(random,
 				(byte) numTotalInfoPieces, (byte) numInitialInfoPieces, alpha,
 				reorderProb, flipsToCheck);
 
 		Factory<Relationship> edgeFactory = new Factory<Relationship>() {
 			@Override
 			public Relationship create() {
 				return new OrderedRelationship();
 			}
 		};
 
 		// Need to start with at least numAttachments vertices; then
 		// add totalSize - numAttachments additional vertices
 		Set<Person> nullSet = new HashSet<Person>();
 		BarabasiAlbertGenerator<Person, Relationship> gen = new BarabasiAlbertGenerator<Person, Relationship>(
 				graphFactory, vertexFactory, edgeFactory, numAttachments,
 				numAttachments, nullSet);
 		gen.evolveGraph(totalPopulation - numAttachments);
 
 		this.graph = (SocialGraph) gen.create();
 
 	}
 
 	/**
 	 * This function needs to exist at the moment because the graph routines
 	 * return a collection, and the other routines are expecting an ordered
 	 * list.
 	 * 
 	 * @param person
 	 * @return
 	 */
 	public List<OrderedPerson> getAdjacencies(OrderedPerson person) {
 		List<OrderedPerson> neighbors = new ArrayList<OrderedPerson>();
 		for (Person nei : graph.getNeighbors(person)) {
 			neighbors.add((OrderedPerson) nei);
 		}
 		return neighbors;
 	}
 
 	/**
 	 * This is the main function of each individual simulation. It is called
 	 * after the model has been parameterized. During each model step, we
 	 * 
 	 * <ul>
 	 * <li>Iterate through all the relationships in the social graph. Since the
 	 * relationships are bi-directional, this gives two one-way relationships.
 	 * For each of these one-way relationships, each piece of knowledge in the
 	 * source is considered. If that piece of knowledge does not exist in the
 	 * destination, then a random check is made against the total probability of
 	 * transfer (xmit * recv probabilities). If this check succeeds, that piece
 	 * of information is transmitted to the adjacent person using
 	 * {@link nardiff.ordered.OrderedPerson#diffuse}</li>
 	 * 
 	 * <li>Iterate through all the people in the social graph. For each user,
 	 * call OrderedPerson.reorder(), which potentially will reorder the person's
 	 * information in an improved way.</li>
 	 * </ul>
 	 * 
 	 * The model keeps calling steps until the termination conditions are met.
 	 * This requires that (1) all the information is diffused to all of the
 	 * edges within the model, and (2) all of the people have the information
 	 * ordered correctly. The simulation tracks when these events occur, and, at
 	 * the termination of the simulation and before the run() method returns,
 	 * writes the data for the simulation using the static reference to
 	 * DataOutputFile out.
 	 * 
 	 * @see nardiff.ordered.OrderedPerson
 	 * 
 	 */
 	@Override
 	public void run() {
 		createGraph();
 
 		boolean continueCondition = true;
 
 		do { // each step...
 
 			// Go through each relationship
 			for (Relationship r : graph.getEdges()) {
 				Pair<Person> people = graph.getEndpoints(r);
 
 				OrderedPerson first = (OrderedPerson) people.getFirst();
 				OrderedPerson second = (OrderedPerson) people.getSecond();
 
 				/*
 				 * The probability of diffusing a piece of information should
 				 * depend on the similarity of the two agents. This is
 				 * determined in the usual way by taking the Levenshtein
 				 * distance between the intersections of knowledge.
 				 */
 
 				float normSimilar = first.getIntersectionSimilarity(second);
 				float probXfer = probKnowledgeXmit * normSimilar;
 
 				// Sanity check; probXfer should be in [0..1]
 				if (probXfer < 0 || probXfer > 1)
 					throw new RuntimeException("ProbXfer is " + probXfer);
 
				// TODO: Extract range limitation to parameter?
				probXfer = (probXfer * 0.6f) + 0.2f; // Range 0.2 -> 0.8
 
 				// Check for f->s
 				if (random.nextBoolean(probXfer)) {
 					int randPos = random.nextInt(first.knowledge.length);
 					if (!second.has(first.knowledge[randPos]))
 						second.diffuse(first.knowledge[randPos],
 								getAdjacencies(second));
 				}
 				// Independent check for s->f
 				if (random.nextBoolean(probXfer)) {
 					int randPos = random.nextInt(second.knowledge.length);
 					if (!first.has(second.knowledge[randPos]))
 						first.diffuse(second.knowledge[randPos],
 								getAdjacencies(first));
 				}
 			}
 
 			// Reorder
 			for (Person p : graph.getVertices()) {
 				OrderedPerson op = (OrderedPerson) p;
 				if (random.nextBoolean(reorderProb))
 					op.reorder(getAdjacencies(op));
 			}
 
 			if (steps % 10 == 0)
 				outputData();
 
 			steps++;
 
 			if (steps > stepsLimit)
 				continueCondition = false;
 
 		} while (continueCondition);
 
 	}
 
 	void outputData() {
 		// Calculate average degree
 		float avgDegree = graph.getEdgeCount() * 2 // *2 b/c undirected graph
 				/ graph.getVertexCount();
 
 		// colNames[0] = "modelID";
 		// colNames[1] = "randomSeed";
 		// colNames[2] = "numPeople";
 		// colNames[3] = "numAttachmentsOnAdd";
 		// colNames[4] = "knowledgeVectorSize";
 		// colNames[5] = "knowledgeVectorInitialFill";
 		// colNames[6] = "probKnowledgeXmit";
 		// colNames[7] = "avgDegree";
 		// colNames[8] = "alpha";
 		// colNames[9] = "reorderProb";
 		// colNames[10] = "step";
 		// colNames[11] = "meanElementsPerPerson";
 		// colNames[12] = "meanProportionOfTotalKnowledge";
 		// colNames[13] = "meanSeenTruthScore";
 		// colNames[14] = "meanTotalTruthScore";
 		// colNames[15] = "ratioTotalKnowledge";
 		// colNames[16] = "ratioTotalOrderedKnowledge";
 
 		Object[] data = new Object[17];
 		data[0] = modelID;
 		data[1] = randomSeed;
 		data[2] = graph.getVertexCount();
 		data[3] = this.numAttachments;
 		data[4] = this.numTotalInfoPieces;
 		data[5] = this.numInitialInfoPieces;
 		data[6] = this.probKnowledgeXmit;
 		data[7] = avgDegree;
 		data[8] = alpha;
 		data[9] = reorderProb;
 		data[10] = steps;
 		data[11] = meanElementsPerPerson();
 		data[12] = meanProportionOfTotalKnowledge();
 		data[13] = meanSeenTruthScore();
 		data[14] = meanTotalTruthScore();
 		data[15] = ratioTotalKnowledge();
 		data[16] = ratioTotalOrderedKnowledge();
 
 		out.writeTuple(data);
 
 	}
 
 	/**
 	 * For debugging purposes.
 	 * 
 	 * @param step
 	 */
 	private void outputState() {
 		System.out.println("State at " + steps);
 
 		float totTruthScore = 0f;
 		for (Person p : graph.getVertices()) {
 			OrderedPerson op = (OrderedPerson) p;
 			byte[] knowledge = op.knowledge;
 			byte[] truth = op.getTrueOrdering();
 			float ldist = LevenshteinDistance.computeDistance(knowledge, truth);
 			float truthScore = (knowledge.length - ldist) / knowledge.length;
 			totTruthScore += truthScore;
 		}
 		float avgTruthScore = totTruthScore / graph.getVertexCount();
 		System.out.println("Avg truth score: " + avgTruthScore);
 
 	}
 
 	public float meanElementsPerPerson() {
 		int numElements = 0;
 		int numPersons = 0;
 
 		for (Person p : graph.getVertices()) {
 			OrderedPerson op = (OrderedPerson) p;
 			numElements += op.knowledge.length;
 			numPersons++;
 		}
 
 		return (float) numElements / numPersons;
 	}
 
 	public float meanProportionOfTotalKnowledge() {
 		float meanElements = meanElementsPerPerson();
 		return (float) meanElements / numTotalInfoPieces;
 	}
 
 	/**
 	 * @return the mean truth score compared with an ordered version with
 	 *         complete information
 	 */
 	public float meanTotalTruthScore() {
 		float totalTruthScore = 0f;
 		int numPersons = 0;
 
 		// Construct a perfect truth (ha!) for comparison purposes
 		byte[] totalTruth = new byte[numTotalInfoPieces];
 		for (int i = 0; i < numTotalInfoPieces; i++)
 			totalTruth[i] = (byte) i;
 
 		for (Person p : graph.getVertices()) {
 			OrderedPerson op = (OrderedPerson) p;
 			int ld = LevenshteinDistance.computeDistance(totalTruth,
 					op.knowledge);
 			float score = OrderedPerson
 					.normalizeDistance(ld, totalTruth.length);
 			totalTruthScore += score;
 			numPersons++;
 		}
 		return (float) totalTruthScore / numPersons;
 	}
 
 	/**
 	 * @return the mean truth score compared with an ordered version of only
 	 *         those elements that a person has.
 	 */
 	public float meanSeenTruthScore() {
 		float totalTruthScore = 0f;
 		int numPersons = 0;
 
 		for (Person p : graph.getVertices()) {
 			OrderedPerson op = (OrderedPerson) p;
 			byte[] orderedKnowledge = op.getTrueOrdering();
 
 			int ld = LevenshteinDistance.computeDistance(orderedKnowledge,
 					op.knowledge);
 			float score = OrderedPerson.normalizeDistance(ld,
 					orderedKnowledge.length);
 			totalTruthScore += score;
 			numPersons++;
 		}
 		return (float) totalTruthScore / (float) numPersons;
 	}
 
 	public float ratioTotalKnowledge() {
 		int numTotalKnowledge = 0;
 		int numPersons = 0;
 
 		for (Person p : graph.getVertices()) {
 			OrderedPerson op = (OrderedPerson) p;
 			if (op.knowledge.length == numTotalInfoPieces)
 				numTotalKnowledge++;
 			numPersons++;
 		}
 
 		return (float) numTotalKnowledge / numPersons;
 	}
 
 	/**
 	 * @return the ratio of persons having both (1) all information pieces and
 	 *         (2) those pieces ordered correctly.
 	 */
 	public float ratioTotalOrderedKnowledge() {
 		int numTotalOrderedKnowledge = 0;
 		int numPersons = 0;
 
 		for (Person p : graph.getVertices()) {
 			OrderedPerson op = (OrderedPerson) p;
 			if (op.knowledge.length == numTotalInfoPieces)
 				if (OrderedPerson.isOrdered(op.knowledge))
 					numTotalOrderedKnowledge++;
 			numPersons++;
 		}
 
 		return (float) numTotalOrderedKnowledge / numPersons;
 	}
 
 }
